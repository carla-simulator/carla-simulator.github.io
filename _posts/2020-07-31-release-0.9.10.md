---
layout: post
comments: true
title:  "CARLA 0.9.10 release"
subtitle: "A new semantic LIDAR sensor, automatic map generation with OpenStretMap, and a brand-new repository for plug-ins made by contributors. These are just some of the many news coming in CARLA 0.9.10."
description: "A new semantic LIDAR sensor, automatic map generation with OpenStretMap, and a brand-new repository for plug-ins made by contributors. These are just some of the many news coming in CARLA 0.9.10."
author: "@sergi-e"
date:   2020-04-22 10:00:00 +0002
image: 'img/carla.jpg'
background: '/img/posts/2019-12-11/Bann001.jpg'
---

To finish the summer on a high note, the long-awaited  __CARLA 0.9.10__ is here! Turn on the AC, and get comfortable. This is going to be an exciting trip.  

CARLA 0.9.10 comes with the trunk packed of improvements, with notable dedication to sensors. Not also has the LIDAR sensor been upgraded, but a brand-new semantic LIDAR sensor is here to provide with much more detailed information. We are working to improve the rendering pipeline for cameras and, on the meantime, some changes in the sky atmosphere have been made for those renders to look even better.  

This idea of renovation extends to other CARLA modules too. The architecture of Traffic Manager has been thoroughly revisited to improve the performance, and ensure consistency. It is now deserving of the name __TM 2.0__. The integration with Autoware has been improved and eased, facilitating an agent that can be used out-of-the-box. These improvements come along with the first integration of CARLA-ROS bridge with __ROS2__, to keep up with the new generation of ROS. Finally, the pedestrian gallery is going under renovation too. We want to provide with a more varied and realistic set of walkers that make the simulation feel alive.  

There are also some worth-mentioning additions. The integration with __OpenStreetMap__ (still experimental), allows users to generate CARLA maps based on the road definitions in [OpenStreetMap](https://www.openstreetmap.org), an open-license world map. A plug-in repository has been created for contributors to share their work, and it already comes with a remarkable contribution. The __carlaviz__ plug-in allows for web browser visualization of the simulation, and it has been developed and maintained by [wx9698](https://github.com/wx9698). We would like to take some extra time to thank all the external contributors that were part of this release. We are grateful for their work, and all their names will figure both in this post, and the release video.  

Last, but not least, we would also like to announce that... __the CARLA AD Leaderboard is finally open to the public!__ To test the driving proficiency of your AD agent, and share the results with the rest of the world. Watch the video at the end of this post, and find out more in the [CARLA AD Leaderboard website](https://leaderboard.carla.org/)! 

Here is a recap of all the novelties in CARLA 0.9.10!

*   __[LIDAR sensor upgrade](#lidar-sensor-upgrade)__ — Better performance, more detailed representation of the world, and additional parameterization for a more realistic behavior of the sensor.  
*   __[Semantic LIDAR sensor](#semantic-lidar-sensor)__ — A new LIDAR sensor providing all the available data per point, and allowing semantic and instance segmentation of its surroundings.  
*   __[OpenStreetMap integration (experimental)](#openstreetmap-integration)__ — A new feature to generate CARLA maps based on an open-license world map.  
*   __[Plug-in repository](#plug-in-repository)__ — A space for CARLA plug-ins and add-ons that are developed and maintained by external contributors.  
*   __[carlaviz plug-in](#carlaviz-plug-in)__ — New plug-in that allows for visualization of the simulation in a web browser. A contribution made by [wx9698](https://github.com/wx9698).  
*   __[Traffic Manager 2.0](#traffic-manager-2.0)__ — A remodelled architecture that improves performance, and fixes possible frame delays when commands are applied.  
*   __[ROS2 integration](#ros2-integration)__ — The CARLA-ROS bridge now provides support for ROS2, the first step to achieve full integration with the next generation of ROS.  
*   __[Autoware integration improvements](#autoware-integration-improvements)__ — Now we provide with an Autoware image with all the content and configuration needed, and an Autoware agent ready to be used.  
*   __[New RSS features](#new-rss-features)__ — Integration of the new features in *ad-rss-lib 4.0.x*, which include pedestrians, and unstructured scenarios.  
*   __[Pedestrian gallery extension](#pedestrian-gallery-extension)__ — The first iteration on a great upgrade of the pedestrians available in CARLA. So far, it features three new models with much more detailed facial features and clothing.  
*   __[New sky atmosphere](#new-sky-atmosphere)__ — Adjustments in the sun light values for a more realistic ambience in the simulation.  
*   __[Contributors](#contributors)__ — A space to thank the external contributions since the release of CARLA 0.9.9.  
*   __[Changelog](#changelog)__ — A summary of the fixes featured in this release.  
*   __[CARLA AD Leaderboard Announcement](#carla-ad-leaderboard-announcement)__ — Watch the video introducing the recently opened CARLA AD Leaderboard.  

Let's take a look!

{% include youtube.html id="dvPhN0Gbb0w" %}

{% include release_button.html release_tag="0.9.10" %}

<br>

## LIDAR sensor upgrade
---

First and foremost, the performance of the LIDAR sensor has been greatly improved. This has been achieved while also providing with new colliders for the elements in the scene. The sensor representation of the world is now more detailed, and the elements in it are described much more accurately.  

![lidar_sensor](/img/posts/2020-31-07/lidar_old.gif){:class="img-fluid"}


Some new attributes have been added to the LIDAR parameterization. These make the sensor and the point cloud behave in a more realistic manner.  

*   __Intensity__ — The `raw_data` retrieved by the LIDAR sensor is now a 4D array of points. The fourth dimension contains an approximation of the intensity of the received ray. The intensity is reduced over time as the ray travels according to the formula:  

```sh
intensity / original_intensity = e * (-attenuation_coef * distance)
```  
The coefficient of attenuation may depend on the sensor's wavelenght and the conditions of the atmosphere. It can be modified with the LIDAR attribute: `atmosphere_attenuation_rate`.  
*   __Drop-off__ — In real sensors, some cloud points can be loss due to multiple reasons like perturbations on the atmosphere or sensor errors. We simulate these with two different models.  
	*   __General drop-off__ — Proportion of points that we drop-off randomly. This is done before the tracing, meaning the points being dropped are not calculated, and therefore performance is increased. If `dropoff_general_rate = 0.5`, half of the points will be dropped.
	*   __Instensity-based drop-off__ — For each point detected, and extra drop-off is calculated with a probability based in the computed intensity. This probability is determined by two parameters. `dropoff_zero_intensity` is the probability of points with zero intensity to be dropped. `dropoff_intensity_limit` is a threshold intensity above which no points will be dropped. The probability of a point within the range to be dropped is a linear proportion based on these two parameters.  
*   __Noise__ — The `noise_stddev` attribute makes for a noise model to simulate unexpected deviations that appear in real-life sensors. If the noise is positive, the location of each point will be randomly perturbed along the vector of the ray detecting it.



## Semantic LIDAR sensor
---

This sensor simulates a rotating LIDAR implemented using ray-casting that exposes all the information about the raycast hit. Its behaviour is quite similar to the LIDAR sensor, but there are two main differences between them.

*   The raw data retrieved by the semantic LIDAR includes more data per point.
	*   Coordinates of the point (as the normal LIDAR does).
	*   The cosine between the angle of incidence and the normal of the surface hit.
	*   Instance and semantic ground-truth. Basically the index of the CARLA object hit, and its semantic tag.
*   The semantic LIDAR does not include neither intensity, drop-off nor noise model attributes.

The capabilities of this sensor are remarkable. A simple visualization of the the Semantic LIDAR data provides with a much clear view of the surroundings.  
<br>
![raycast_lidar_sensor](/img/posts/2020-31-07/lidar_raycast.gif){:class="img-fluid"}

## OpenStreetMap integration
---

<div class="alert alert-warning">
  <small><i><strong>Warning!</strong> This feature is still in experimental phase.</i></small>
</div>

OpenStreetMap is an open license map of the world developed by contributors. Sections of these map can be exported to an XML file in `.osm` format. CARLA can convert this file to OpenDRIVE format, and ingest it as any other OpenDRIVE map using the [OpenDRIVE Standalone Mode](https://carla.readthedocs.io/en/latest/adv_opendrive/). The process is detailed in the [documentation](https://carla.readthedocs.io/en/latest/tuto_G_openstreetmap/), but here is a summary.  

__1. Obtain a map with OpenStreetMap__ — Go to [OpenStreetMap](https://www.openstreetmap.org), and export the XML file containing the map information.  

__2. Convert to OpenDRIVE format__ — To do the conversion from `.osm` to `.xodr` format, two classes have been added to the Python API.  

*   __[carla.Osm2Odr](https://carla.readthedocs.io/en/latest/python_api/#carlaosm2odr)__ – The class that does the conversion. It takes the content of the `.osm` parsed as string, and returns a string containing the resulting `.xodr`.  
	*   `osm_file` — The content of the initial `.osm` file parsed as string.  
	*   `settings` — A [carla.Osm2OdrSettings](https://carla.readthedocs.io/en/latest/python_api/#carlaosm2odrsettings) object containing the settings for the conversion.  
*   __[carla.Osm2OdrSettings](https://carla.readthedocs.io/en/latest/python_api/#carlaosm2odrsettings)__ – Helper class that contains different parameters used during the conversion.  
	*   `use_offsets` *(default False)* — Determines whereas the map should be generated with an offset, thus moving the origin from the center according to that offset.  
	*   `offset_x` *(default 0.0)* — Offset in the X axis.  
	*   `offset_y` *(default 0.0)* — Offset in the Y axis.  
	*   `default_lane_width` *(default 4.0)* — Determines the width that lanes should have in the resulting XODR file.  
	*   `elevation_layer_height` *(default 0.0)* — Determines the height separating elements in different layers, used for overlapping elements. [Read more on layers](https://wiki.openstreetmap.org/wiki/Key:layer) for a better understanding of this.  


__3. Import into CARLA__ – The OpenDRIVE file can be automatically ingested in CARLA using the [OpenDRIVE Standalone Mode](https://carla.readthedocs.io/en/latest/adv_opendrive/). Use either a customized script or the `config.py` example provided in CARLA.  

Here is an example of the feature at work. The image above is the official [OpenStreetMap](https://www.openstreetmap.org) page. The image below is a fragment of that map area ingested in CARLA.  <br>

![osm_web](/img/posts/2020-31-07/osm_web.jpg){:class="img-fluid"}


![osm_carla](/img/posts/2020-31-07/osm_carla.jpg){:class="img-fluid"}

## Plug-in repository
---

A new repository has been created purposely for external contributions. This is meant to be a space for contributors to develop and maintain their plug-ins and add-ons for CARLA.  

Take the chance, and share your work in the [plug-in repository](https://github.com/carla-simulator/carla-plugins)! CARLA is grateful to all the [contributors](#contributors) who dedicate their time to help the project grow, and this is the perfect space to make their hard work visible for everybody.  


## carlaviz plug-in
---

This plug-in was created by the contributor [wx9698](https://github.com/wx9698), and it already figures in the [carla plug-ins repository](https://github.com/carla-simulator/carla-plugins).  
The plug-in creates a web browser window with some basic representation of the scene. Actors are updated on-the-fly, sensor data can be retrieved, and additional text, lines and polylines can be drawn in the scene.  

There is detailed [carlaviz documentation](https://carla.readthedocs.io/en/latest/plugins_carlaviz/) already available, but here is a brief summary on how to run the plug-in and the output it provides.  

__1. Download carlaviz.__  

```sh
# Pull only the image that matches the CARLA package being used
docker pull mjxu96/carlaviz:0.9.6
docker pull mjxu96/carlaviz:0.9.7
docker pull mjxu96/carlaviz:0.9.8
docker pull mjxu96/carlaviz:0.9.9

# Pull this image if working on a CARLA build from source
docker pull carlasim/carlaviz:latest
```

__2. Run CARLA.__  

__3. Run carlaviz.__ In another terminal run the following command. Change `<name_of_Docker_image>` for the name of the image previously downloaded.  
E.g. `carlasim/carlaviz:latest` or `mjxu96/carlaviz:0.9.9`.  

```sh
docker run -it --network="host" -e CARLAVIZ_HOST_IP=localhost -e CARLA_SERVER_IP=localhost -e CARLA_SERVER_PORT=2000 <name_of_Docker_image>
```
__4. Open the localhost__ carlaviz runs by default in port `8080`. Open your web browser and go to `http://127.0.0.1:8080/`.  

The plug-in shows a visualization window on the right. The scene is updated in real-time. A sidebar on the left side contains a list of items to be shown. Some of these items will appear in the visualization window, others (mainly sensor and game data) appear just above the item list. The result will look similar to the following.  

![carlaviz](/img/posts/2020-31-07/carlaviz.gif){:class="img-fluid"}

## Traffic Manager 2.0
---

For this iteration, the inner structure and logic of the Traffic Manager module has been revamped. These changes are explained in detail in the [Traffic Manager documentation](https://carla.readthedocs.io/en/latest/adv_traffic_manager/). Here is a brief summary of the principles that set the ground for the new architecture.  

*   __Data query centralization.__ The most impactful component in the new Traffic Manager 2.0 logic is the ALSM. It takes care of all the server calls necessary to get the current state of the simulation, and stores everything that will be needed further on: lists of vehicles and walkers, their position and velocity, static attributes such as bounding boxes, etc. Everything is queried by the ALSM and cached so that computational cost is reduced, and redundant API calls are avoided. Additionally, these will be used by different components, such as paths. Vehicle tracking is externalized in other components, so that there is no information dependency.  

*   __Per-vehicle loop structure.__ Previously in Traffic Manager, the calculations were divided in global stages. They were self-contained, which made it difficult to save up computational costs. Later in the pipeline, stages had no knowledge of the vehicle calculations done previously. Changing these global stages to a per-vehicle structure makes it easier to implement features such as parallellization, as the processing of stages can be triggered externally.  

*   __Loop control.__ This per-vehicle structure brings another issue: synchronization between vehicles has to be guaranteed. For said reason, a component is created to control the loop of the vehicle calculations. This controller creates synchronization barriers that force each vehicle to wait for the rest to finish their calculations. Once all the vehicles are done, the following stage is triggered. That ensures that all the vehicle calculations are done in sync, and avoids frame delays between the processing cycle and the commands being applied.  

## ROS2 integration
---

The CARLA-ROS bridge now provides support for the new generation of ROS. This integration is still a work in progress, and the current state can be followed in the corresponding [ros2 branch](https://github.com/carla-simulator/ros-bridge/tree/ros2). 


## Autoware integration improvements
---

The [CARLA-Autoware bridge](https://github.com/Autoware-AI/simulation/tree/master/carla_simulator_bridge) is now part of the official Autoware repository.
The bridge relies on the [CARLA ROS Bridge](https://github.com/carla-simulator/ros-bridge) and its main objective is to establish the communication between
the CARLA world and Autoware (mainly  through ROS datatypes conversions).

The [CARLA-Autoware repository](https://github.com/carla-simulator/carla-autoware) contains an example of usage, with an Autoware agent ready to be used out-of-the-box. The agent is provided as a Docker image with all the necessary components already included. It features:  

*  Autoware 1.14.0.
*  The [Autoware content repository](https://bitbucket.org/carla-simulator/autoware-contents/src/master/). This repository contains additional data required to run Autoware with CARLA, such as point cloud maps, vector maps, and some configuration files.  
*  CARLA ROS bridge.

The agent's configuration, including sensor configuration, can be found [here](https://github.com/carla-simulator/carla-autoware/tree/master/carla-autoware-agent/agent).

#### Executing the agent

__1. Clone the [carla-autoware repository](https://github.com/carla-simulator/carla-autoware).__  
```sh
git clone --recurse-submodules https://github.com/carla-simulator/carla-autoware
```
__2. Build the docker image.__
```sh
cd carla-autoware
./build.sh
```
__3. Run a CARLA server.__ 
You can either run the CARLA server in your host machine or within a Docker container. Find out more [here](https://carla.readthedocs.io/en/latest/build_docker/).

__4. Run the carla-autoware image.__ This will start an interactive shell inside the container.  

```sh
./run.sh
```
__5. Run the agent.__

```sh
roslaunch carla_autoware_agent carla_autoware_agent.launch town:=Town01
```

__6. Select the desired destination.__ Use the `2D Nav Goal` button in [RVIZ](http://wiki.ros.org/rviz). The output will be similar to the following.  

![autoware_agent](/img/posts/2020-31-07/autoware_agent.gif){:class="img-fluid"}

## New RSS features
---

The RSS sensor in CARLA now has full support for [ad-rss-lib 4.0.x](https://github.com/intel/ad-rss-lib/releases), which includes two main features.  

*   __Unstructured roads__ — To keep it simple, scenarios were vehicles move in a route where no specific lanes are defined. 

![rss_unstructured](/img/posts/2020-31-07/rss_unstructured.gif){:class="img-fluid"}

*   __Pedestrians__ — Moving in both structured and structured scenarios.  

![rss_pedestrians](/img/posts/2020-31-07/rss_pedestrians.gif){:class="img-fluid"}

Find out more about these features either in the original [RSS paper](https://arxiv.org/abs/1708.06374), or reading the rss-lib documentation on [unstructured scenes](https://intel.github.io/ad-rss-lib/ad_rss/UnstructuredScenes/), and [behavior model for pedestrians](https://intel.github.io/ad-rss-lib/ad_rss/UnstructuredScenes/#behavior-modeltrajectory-calculation).  


## Pedestrian gallery extension
---

This release includes the first iteration on a major extension of the pedestrian gallery. In order to recreate reality more accurately, one of our main goals is to provide with a more diverse set of walkers. Moreover, great emphasis is being put in the details: meticulous models, attention to facial features, new shaders and materials for their skin, hair, eyes... In summary, we want to make them, and therefore the simulation, feel alive.  

So far, there are three new models in the blueprint library, a sneak peek on what is to come. Let's see how things are going!  

![pedestrians_models](/img/posts/2020-31-07/pedestrians_models02.png){:class="img-fluid"}

![pedestrians_faces](/img/posts/2020-31-07/pedestrians_faces.png){:class="img-fluid"}


## New sky atmosphere
---

The sun light of the simulation has been adjusted to values closer to reality (by Unreal Engine standards). Due to these changes, the default values of the RGB camera sensor have been balanced accordingly, so now its parameterization is also more realistic.  

*<should we mention this??!!>*  
An additional configuration must be taken into account. In order to save the user having to change the RGB camera attributes depending on the sun altitude, the light values of the scene are altered when the sun position changes, so that a RGB camera with default values always renders appealing images.  

![sky_atmosphere](/img/posts/2020-31-07/sky_atmosphere.jpg){:class="img-fluid"}

## Contributors
---

We would like to dedicate this space to all of those whose contributions were merged in any of the project's GitHub repositories during the development of CARLA 0.9.10. Thanks a lot for your hard work!

- [arkadiy-telegin](https://github.com/arkadiy-telegin)  
- [Bitfroest](https://github.com/Bitfroest)  
- [dennisrmaier](https://github.com/dennisrmaier)  
- [Diego-ort](https://github.com/Diego-ort)  
- [eleurent](https://github.com/eleurent)  
- [elvircrn](https://github.com/elvircrn)  
- [Hakhyun-Kim](https://github.com/Hakhyun-Kim)  
- [hofbi](https://github.com/hofbi)  
- [ICGog](https://github.com/ICGog)  
- [ItsTimmy](https://github.com/ItsTimmy)  
- [johschmitz](https://github.com/johschmitz)  
- [kbu9299](https://github.com/kbu9299)  
- [ll7](https://github.com/ll7)  
- [patmalcolm91](https://github.com/patmalcolm91)  
- [pedroburito](https://github.com/pedroburito)  
- [PhDittmann](https://github.com/PhDittmann)  
- [s-hillerk](https://github.com/s-hillerk)  
- [squizz617](https://github.com/squizz617)  
- [umateusz](https://github.com/umateusz)  
- [Vaan5](https://github.com/Vaan5)  
- [wx9698](https://github.com/wx9698)  

## Changelog
---

  + Upgraded carla Docker image to Ubuntu 18.04
  + Added PythonAPI `carla.Osm2Odr.convert()` function and `calra.Osm2OdrSettings` class to support Open Street Maps to OpenDRIVE conversions
  + Upgraded to AD RSS v4.0.1 supporting unstructured scenes and pedestrians.
  + Changed frozen behavior for traffic lights. It now affects to all traffic lights at the same time.
  + Added API function `freeze_all_traffic_lights` and `reset_group`.
  + Added Light ids.
  + Added vehicle light and street light data to recorder.
  + Added API function `add_angular_impulse()` to add angular impulse to any actor.
  + All sensors are now multi-stream, that means that the same sensor can be listened from different clients.
  + Exposed matrix form of transformation to the client and Python API.
  + Added make command to download contributions as plugins (`make plugins`).
  + Added PythonAPI command to set multiple car light states at once.
  + Added PythonAPI `carla.world.get_vehicles_light_states` to get all the car light states at once.
  + Added a warning if the user tries to use the SpringArm exactly in the 'z' axis of the attached actor.
  + Improved the LiDAR and Radar sensors with a parallel implentation of the raycasting.
  + Added an approximation of the intensity of each point of the cloud in the LiDAR sensor.
  + Added Dynamic Vision Sensor (DVS) camera based on ESIM simulation http://rpg.ifi.uzh.ch/esim.html.
  + Improved LiDAR and radar to better match the shape of the vehicles.
  + Added support for additional TraCI clients in Sumo co-simulation.
  + Added API functions `get_right_vector` and `get_up_vector`.
  + Added default values and a warning message for lanes missing the width parameter in OpenDRIVE.
  + Added parameter to enable/disable pedestrian navigation in standalone mode.
  + Improved mesh split in standalone mode.
  + Added Renderdoc plugin to the Unreal project.
  + Added configurable noise to Lidar sensor.
  + Replace deprectated `platform.dist()` with recommended `distro.linux_distribution()`.

##### Fixes
  + Fixed a bug where `get_traffic_light` would always return `None`.
  + Fixed recorder determinism problems.
  + Fixed rain drop spawn issues when spawning camera sensors.
  + Fixed assets import pipeline.
  + Fixed Update.sh from failing when the root folder contains a space on it.
  + Fixed colors of lane markings when importing a map, they were reversed (white and yellow).
  + Fixed missing include directive in file **WheelPhysicsControl.h**.
  + Fixed gravity measurement bug from IMU sensor.
  + Fixed point cloud of LiDAR. Now the points are given correctly in the sensor's coordinate system.
  + Fixed OpenDRIVE ingestion bugs.
  + Fixed delay in the tcp communication from server to client, improving performance in synchronous mode in linux systems.
  + Fixed large RAM usage when loading polinomial geometry from OpenDRIVE.
  + Fixed collision issues when debug draw(debug.draw_line) is called.
  + Fixed Gyroscope sensor to properly give angular velocity readings in local frame.


## CARLA AD Leaderboard Announcement
---

Find out more in the [official site](https://leaderboard.carla.org/)!   

{% include youtube.html id="-L9VuPpzVdQ" %}
